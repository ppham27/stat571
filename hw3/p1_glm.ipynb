{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import linalg\n",
    "from typing import Callable, List, NamedTuple, Sequence, Tuple\n",
    "\n",
    "BETA = np.array([0., 0.5], dtype=np.float64)\n",
    "DESIGN_CLUSTERS = {\n",
    "    'I': [[7, 10, 13, 16]],\n",
    "    'II': [[7, 10, 13], [7, 10, 16], [7, 13, 16], [10, 13, 16]],\n",
    "}\n",
    "NUM_CLUSTERS = [15, 30, 60]\n",
    "WITHIN_CLUSTER_CORRELATIONS = [0.5, 0.9]\n",
    "\n",
    "CorrelationStructure = enum.Enum(\n",
    "    'CorrelationStructure',\n",
    "    'NONE EXCHANGEABLE EXPONENTIAL')\n",
    "\n",
    "EstimationMethod = enum.Enum(\n",
    "    'EstimationMethod',\n",
    "    'OLS QL Sandwich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(NamedTuple('Experiment', [\n",
    "    ('beta', np.array),\n",
    "    ('error_variance', float),\n",
    "    ('num_clusters', Sequence[Tuple[np.array, np.array]]),\n",
    "    ('clusters', Sequence[np.array]),\n",
    "    ('within_cluster_correlation', float),\n",
    "    ('within_cluster_correlation_structure', CorrelationStructure),\n",
    "])):\n",
    "    \"\"\"Encapsulates parameters for the data generating mechanism.\"\"\"\n",
    "    \n",
    "    def sample_clusters(self) -> List[Tuple[np.array, np.array]]:\n",
    "        return [self._sample_cluster() for _ in range(self.num_clusters)]\n",
    "    \n",
    "    def _sample_cluster(self) -> Tuple[np.array, np.array]:\n",
    "        covariates = self._sample_cluster_covariates()\n",
    "        covariates = np.column_stack((np.ones(len(covariates)), covariates))\n",
    "        covariance = self._make_within_cluster_covariance(len(covariates))\n",
    "        response = stats.multivariate_normal(\n",
    "            mean=np.matmul(covariates, self.beta), cov=covariance).rvs()\n",
    "        return covariates, response\n",
    "    \n",
    "    def _sample_cluster_covariates(self) -> np.array:\n",
    "        return self.clusters[np.random.choice(len(self.clusters))]\n",
    "    \n",
    "    def _make_within_cluster_covariance(self, cluster_size):\n",
    "        correlation = np.eye(cluster_size)\n",
    "        if self.within_cluster_correlation_structure == CorrelationStructure.EXCHANGEABLE:\n",
    "            correlation[correlation == 0] = self.within_cluster_correlation\n",
    "        elif self.within_cluster_correlation_structure == CorrelationStructure.EXPONENTIAL:\n",
    "            for i in range(cluster_size):\n",
    "                for j in range(i + 1, cluster_size):\n",
    "                    correlation[i, j] = correlation[j, i] = np.power(\n",
    "                        self.within_cluster_correlation, np.abs(j - i))\n",
    "        return self.error_variance*correlation\n",
    "        \n",
    "    @classmethod\n",
    "    def from_template(\n",
    "        cls,\n",
    "        clusters,\n",
    "        num_clusters,\n",
    "        within_cluster_correlation,\n",
    "        within_cluster_correlation_structure) -> 'Experiment':\n",
    "        assert len(set([len(cluster) for cluster in clusters])) == 1,\\\n",
    "               'Clusters must be the same size.'\n",
    "        \n",
    "        return cls(beta=BETA,\n",
    "                   clusters=clusters,\n",
    "                   error_variance=1.,\n",
    "                   num_clusters=num_clusters,\n",
    "                   within_cluster_correlation=within_cluster_correlation,\n",
    "                   within_cluster_correlation_structure=within_cluster_correlation_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8140454723739351\n",
      "0.8773015400721659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'OLS': {'EXCHANGEABLE': 0.0,\n",
       "  'EXPONENTIAL': 0.0,\n",
       "  'NONE': 0.004714045207910317},\n",
       " 'QL': {'EXCHANGEABLE': 0.5, 'EXPONENTIAL': 0.0, 'NONE': 0.004662787355928457},\n",
       " 'Sandwich': {'EXCHANGEABLE': 0.0,\n",
       "  'EXPONENTIAL': 0.0,\n",
       "  'NONE': 0.0046641498322187724}}"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_rho(epsilon_hat):\n",
    "    covariance = np.outer(epsilon_hat, epsilon_hat)    \n",
    "    rho_exchangeable = 0.\n",
    "    rho_exponential = 0.\n",
    "    for i in range(len(covariance)):\n",
    "        for j in range(i + 1, len(covariance[i])):\n",
    "            rho_exchangeable += covariance[i, j]\n",
    "            if j - i == 1:\n",
    "                rho_exponential += covariance[i, j]\n",
    "    cluster_pairwise_count = (covariance.shape[0] - 1)*(covariance.shape[1] - 2)\n",
    "    rho_exchangeable /= cluster_pairwise_count\n",
    "    rho_exponential /= covariance.shape[0] - 1\n",
    "    return rho_exchangeable, rho_exponential\n",
    "    \n",
    "def run_experiment(experiment):\n",
    "    clusters = experiment.sample_clusters()\n",
    "    X = np.vstack([X for X, _ in clusters])\n",
    "    y = np.hstack([y for _, y in clusters])\n",
    "    \n",
    "    gram_matrix = X.T.dot(X)\n",
    "    gram_matrix_inv = linalg.cho_solve(linalg.cho_factor(gram_matrix), np.eye(len(gram_matrix)))\n",
    "    \n",
    "    beta_hat = gram_matrix_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    epsilon_hat = y - X.dot(beta_hat)\n",
    "    sigma_2_hat = epsilon_hat.dot(epsilon_hat)/(len(y) - len(beta_hat))\n",
    "    \n",
    "\n",
    "    sandwich_variance = gram_matrix_inv.dot(\n",
    "        X.T.dot(np.diag(np.square(epsilon_hat))).dot(X)).dot(gram_matrix_inv)\n",
    "    \n",
    "    rho_exchangeable = 0.\n",
    "    rho_exponential = 0.        \n",
    "    for cluster_X, cluster_y in clusters:\n",
    "        cluster_rho_exchangeable, cluster_rho_exponential = estimate_rho(\n",
    "            cluster_y - cluster_X.dot(beta_hat))\n",
    "        rho_exchangeable += cluster_rho_exchangeable\n",
    "        rho_exponential += cluster_rho_exponential\n",
    "                                              \n",
    "    rho_exchangeable /= len(clusters)\n",
    "    rho_exponential /= len(clusters)\n",
    "    print(rho_exchangeable)\n",
    "    print(rho_exponential)\n",
    "        \n",
    "    return {\n",
    "        EstimationMethod.OLS.name: {\n",
    "            CorrelationStructure.NONE.name: np.sqrt(gram_matrix_inv[1, 1]),\n",
    "            CorrelationStructure.EXCHANGEABLE.name: 0.,\n",
    "            CorrelationStructure.EXPONENTIAL.name: 0.,\n",
    "        },\n",
    "        EstimationMethod.QL.name: {\n",
    "            CorrelationStructure.NONE.name: np.sqrt(gram_matrix_inv[1, 1]*sigma_2_hat),\n",
    "            CorrelationStructure.EXCHANGEABLE.name: 0.5,\n",
    "            CorrelationStructure.EXPONENTIAL.name: 0.,            \n",
    "        },\n",
    "        EstimationMethod.Sandwich.name: {\n",
    "            CorrelationStructure.NONE.name: np.sqrt(sandwich_variance[1, 1]),\n",
    "            CorrelationStructure.EXCHANGEABLE.name: 0.,\n",
    "            CorrelationStructure.EXPONENTIAL.name: 0.,\n",
    "        },\n",
    "    }\n",
    "\n",
    "def run_experiments(experiment, num_trials):\n",
    "    def _merge_results(acc, result):\n",
    "        if type(acc) == dict:        \n",
    "            return {key: _merge_results(value, result[key]) for key, value in acc.items()}   \n",
    "        elif type(acc) in {np.float64, float, int}:\n",
    "            return acc + result        \n",
    "        raise ValueError('Unknown type: {}'.format(type(acc).__name__))\n",
    "        \n",
    "    def _divide_results(results, d):\n",
    "        if type(results) == dict:\n",
    "            return {key: _divide_results(value, d) for key, value in results.items()}\n",
    "        return results/d\n",
    "                    \n",
    "    results = [run_experiment(experiment) for _ in range(num_trials)]\n",
    "    results = functools.reduce(_merge_results, results)\n",
    "    return _divide_results(results, num_trials)\n",
    "\n",
    "experiment = Experiment.from_template(\n",
    "    DESIGN_CLUSTERS['I'],\n",
    "    #NUM_CLUSTERS[2],\n",
    "    1000,\n",
    "    WITHIN_CLUSTER_CORRELATIONS[1],\n",
    "    CorrelationStructure.EXPONENTIAL)\n",
    "\n",
    "#tmp = run_experiments(experiment, 128)\n",
    "tmp = run_experiment(experiment)\n",
    "#experiment.sample_clusters()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OLS       NONE            0.9\n",
       "          EXCHANGEABLE    0.5\n",
       "          EXPONENTIAL     0.0\n",
       "QL        NONE            0.0\n",
       "          EXCHANGEABLE    0.0\n",
       "          EXPONENTIAL     0.0\n",
       "Sandwich  NONE            0.0\n",
       "          EXCHANGEABLE    0.0\n",
       "          EXPONENTIAL     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(tmp, orient='index').stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('OLS', 'EXCHANGEABLE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('OLS', 'EXPONENTIAL'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('OLS', 'NONE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('QL', 'EXCHANGEABLE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.5,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('QL', 'EXPONENTIAL'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('QL', 'NONE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.9,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('Sandwich', 'EXCHANGEABLE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('Sandwich', 'EXPONENTIAL'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('Sandwich', 'NONE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan}}"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def index_experiment(experiment):    \n",
    "    return (experiment.num_clusters,\n",
    "            [k for k, v in DESIGN_CLUSTERS.items() if experiment.clusters == v][0],\n",
    "            experiment.within_cluster_correlation_structure.name,\n",
    "            experiment.within_cluster_correlation)\n",
    "\n",
    "simulation_results = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product(\n",
    "        [NUM_CLUSTERS, DESIGN_CLUSTERS.keys(),\n",
    "         [CorrelationStructure.EXCHANGEABLE.name, CorrelationStructure.EXPONENTIAL.name],\n",
    "         WITHIN_CLUSTER_CORRELATIONS],\n",
    "        names=['$n$', 'Design', 'Correlation structure', 'Correlation']),\n",
    "    columns=pd.MultiIndex.from_product(\n",
    "        [[value.name for value in EstimationMethod],\n",
    "         [value.name for value in CorrelationStructure]],\n",
    "        names=['Estimator', 'Assumed correlation']\n",
    "    ))\n",
    "\n",
    "simulation_results.loc[index_experiment(experiment)] = (\n",
    "    pd.DataFrame.from_dict(tmp, orient='index').stack())\n",
    "simulation_results.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CorrelationStructure.NONE: 1>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-a7ccf15b157b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "np.random.choice([[7, 9], [2, 3], [1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.5, 0.5, 0.5],\n",
       "       [0.5, 1. , 0.5, 0.5],\n",
       "       [0.5, 0.5, 1. , 0.5],\n",
       "       [0.5, 0.5, 0.5, 1. ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linalg.cholesky(tmp).T.dot(linalg.cholesky(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6, -0.4, -0.4, -0.4],\n",
       "       [-0.4,  1.6, -0.4, -0.4],\n",
       "       [-0.4, -0.4,  1.6, -0.4],\n",
       "       [-0.4, -0.4, -0.4,  1.6]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linalg.inv(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28867513459481287"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3)/6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
