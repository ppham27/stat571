{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import linalg\n",
    "from typing import Callable, List, NamedTuple, Sequence, Tuple\n",
    "\n",
    "BETA = np.array([0., 0.5], dtype=np.float64)\n",
    "DESIGN_CLUSTERS = {\n",
    "    'I': [[7, 10, 13, 16]],\n",
    "    'II': [[7, 10, 13], [7, 10, 16], [7, 13, 16], [10, 13, 16]],\n",
    "}\n",
    "NUM_CLUSTERS = [15, 30, 60]\n",
    "WITHIN_CLUSTER_CORRELATIONS = [0.5, 0.9]\n",
    "\n",
    "CorrelationStructure = enum.Enum(\n",
    "    'CorrelationStructure',\n",
    "    'NONE EXCHANGEABLE EXPONENTIAL')\n",
    "\n",
    "EstimationMethod = enum.Enum(\n",
    "    'EstimationMethod',\n",
    "    'GLS QL Sandwich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(NamedTuple('Experiment', [\n",
    "    ('beta', np.array),\n",
    "    ('error_variance', float),\n",
    "    ('num_clusters', Sequence[Tuple[np.array, np.array]]),\n",
    "    ('clusters', Sequence[np.array]),\n",
    "    ('within_cluster_correlation', float),\n",
    "    ('within_cluster_correlation_structure', CorrelationStructure),\n",
    "])):\n",
    "    \"\"\"Encapsulates parameters for the data generating mechanism.\"\"\"\n",
    "    \n",
    "    def sample_clusters(self) -> List[Tuple[np.array, np.array]]:\n",
    "        return [self._sample_cluster() for _ in range(self.num_clusters)]\n",
    "    \n",
    "    def _sample_cluster(self) -> Tuple[np.array, np.array]:\n",
    "        covariates = self._sample_cluster_covariates()\n",
    "        covariates = np.column_stack((np.ones(len(covariates)), covariates))\n",
    "        covariance = self._make_within_cluster_covariance(len(covariates))\n",
    "        response = stats.multivariate_normal(\n",
    "            mean=np.matmul(covariates, self.beta), cov=covariance).rvs()\n",
    "        return covariates, response\n",
    "    \n",
    "    def _sample_cluster_covariates(self) -> np.array:\n",
    "        return self.clusters[np.random.choice(len(self.clusters))]\n",
    "    \n",
    "    def _make_within_cluster_covariance(self, cluster_size):\n",
    "        correlation = np.eye(cluster_size)\n",
    "        if self.within_cluster_correlation_structure == CorrelationStructure.EXCHANGEABLE:\n",
    "            correlation[correlation == 0] = self.within_cluster_correlation\n",
    "        elif self.within_cluster_correlation_structure == CorrelationStructure.EXPONENTIAL:\n",
    "            for i in range(cluster_size):\n",
    "                for j in range(i + 1, cluster_size):\n",
    "                    correlation[i, j] = correlation[j, i] = np.power(\n",
    "                        self.within_cluster_correlation, np.abs(j - i))\n",
    "        return self.error_variance*correlation\n",
    "        \n",
    "    @classmethod\n",
    "    def from_template(\n",
    "        cls,\n",
    "        clusters,\n",
    "        num_clusters,\n",
    "        within_cluster_correlation,\n",
    "        within_cluster_correlation_structure) -> 'Experiment':\n",
    "        assert len(set([len(cluster) for cluster in clusters])) == 1,\\\n",
    "               'Clusters must be the same size.'\n",
    "        \n",
    "        return cls(beta=BETA,\n",
    "                   clusters=clusters,\n",
    "                   error_variance=1.,\n",
    "                   num_clusters=num_clusters,\n",
    "                   within_cluster_correlation=within_cluster_correlation,\n",
    "                   within_cluster_correlation_structure=within_cluster_correlation_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_dict(acc, result):\n",
    "    if type(acc) == dict:        \n",
    "        return {key: sum_dict(value, result[key]) for key, value in acc.items()}   \n",
    "    return acc + result\n",
    "    \n",
    "def divide_dict(results, d):\n",
    "    if type(results) == dict:\n",
    "        return {key: divide_dict(value, d) for key, value in results.items()}\n",
    "    return results/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GLS': {'EXCHANGEABLE': 0.015576944643173045,\n",
       "  'EXPONENTIAL': 0.018950136586479142,\n",
       "  'NONE': 0.019245008972987462},\n",
       " 'QL': {'EXCHANGEABLE': 0.015503838166205111,\n",
       "  'EXPONENTIAL': 0.018877295232905236,\n",
       "  'NONE': 0.019179316383929827},\n",
       " 'Sandwich': {'EXCHANGEABLE': 0.0, 'EXPONENTIAL': 0.0, 'NONE': 0.0}}"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_rho(epsilon_hat):\n",
    "    covariance = np.outer(epsilon_hat, epsilon_hat)    \n",
    "    rho_exchangeable = 0.\n",
    "    rho_exponential = 0.\n",
    "    for i in range(len(covariance)):\n",
    "        for j in range(i + 1, len(covariance[i])):\n",
    "            rho_exchangeable += covariance[i, j]\n",
    "            if j - i == 1:\n",
    "                rho_exponential += covariance[i, j]\n",
    "    cluster_pairwise_count = (covariance.shape[0] - 1)*(covariance.shape[1] - 2)\n",
    "    rho_exchangeable /= (np.square(covariance.shape[0]) - covariance.shape[0])/2\n",
    "    rho_exponential /= covariance.shape[0] - 1\n",
    "    return rho_exchangeable, rho_exponential\n",
    "\n",
    "def make_correlation_matrices(clusters, beta_hat, sigma_2_hat):\n",
    "    rho_exchangeable = 0.\n",
    "    rho_exponential = 0.        \n",
    "    for X, y in clusters:\n",
    "        cluster_rho_exchangeable, cluster_rho_exponential = estimate_rho(\n",
    "            (y - X.dot(beta_hat))/np.sqrt(sigma_2_hat))\n",
    "        rho_exchangeable += cluster_rho_exchangeable\n",
    "        rho_exponential += cluster_rho_exponential\n",
    "            \n",
    "    rho_exchangeable /= len(clusters)\n",
    "    rho_exponential /= len(clusters)\n",
    "    \n",
    "    correlation_matrices = []\n",
    "    for X, y in clusters:\n",
    "        exchangeable_matrix = np.eye(len(y))\n",
    "        exchangeable_matrix[exchangeable_matrix == 0] = rho_exchangeable\n",
    "        exponential_matrix = np.eye(len(y))\n",
    "        for i in range(len(y) - 1):\n",
    "            for j in range(i + 1, len(y)):\n",
    "                exponential_matrix[i, j] = exponential_matrix[j, i] = np.power(rho_exponential, j - i)\n",
    "        correlation_matrices.append({\n",
    "            CorrelationStructure.NONE.name: np.eye(len(y)),\n",
    "            CorrelationStructure.EXCHANGEABLE.name: exchangeable_matrix,\n",
    "            CorrelationStructure.EXPONENTIAL.name: exponential_matrix,            \n",
    "        })\n",
    "        \n",
    "    return correlation_matrices\n",
    "\n",
    "def estimate_beta_hats(clusters, correlation_matrices):\n",
    "    def estimate_beta_hat(X, y, correlation_matrix):\n",
    "        weight = linalg.cho_solve(\n",
    "            linalg.cho_factor(correlation_matrix), np.eye(len(correlation_matrix)))\n",
    "        gram_matrix = linalg.cho_factor(X.T.dot(weight).dot(X))\n",
    "        return linalg.cho_solve(gram_matrix, X.T.dot(weight).dot(y))\n",
    "    \n",
    "    beta_hats = [\n",
    "        {\n",
    "            key: estimate_beta_hat(X, y, inv_weight)\n",
    "            for key, inv_weight in inv_weights.items()\n",
    "        } for (X, y), inv_weights in zip(clusters, correlation_matrices)\n",
    "    ]\n",
    "    return divide_dict(functools.reduce(sum_dict, beta_hats), len(beta_hats))\n",
    "\n",
    "def estimate_covariance(clusters,\n",
    "                        correlation_matrices,\n",
    "                        method,\n",
    "                        beta_hat):\n",
    "    if method != EstimationMethod.Sandwich:\n",
    "        covariance = np.zeros((len(beta_hat), len(beta_hat)))\n",
    "        dispersion_factor = 0.\n",
    "        total = 0.\n",
    "        for (X, y), correlation_matrix in zip(clusters, correlation_matrices):\n",
    "            weight = linalg.cho_solve(\n",
    "                linalg.cho_factor(correlation_matrix), np.eye(len(correlation_matrix)))\n",
    "            covariance += X.T.dot(weight).dot(X)\n",
    "            dispersion_factor += np.sum(np.square(y - X.dot(beta_hat)))\n",
    "            total += len(y)\n",
    "        covariance = linalg.cho_solve(linalg.cho_factor(covariance), np.eye(len(beta_hat)))\n",
    "        dispersion_factor /= total - len(beta_hat)\n",
    "        return covariance if method == EstimationMethod.GLS else covariance*dispersion_factor\n",
    "    \n",
    "    return np.zeros((len(beta_hat), len(beta_hat)))\n",
    "    \n",
    "def run_experiment(experiment, estimate_beta=False):\n",
    "    clusters = experiment.sample_clusters()\n",
    "    X = np.vstack([X for X, _ in clusters])\n",
    "    y = np.hstack([y for _, y in clusters])\n",
    "    \n",
    "    gram_matrix_ols = X.T.dot(X)\n",
    "    \n",
    "    beta_hat_ols = linalg.cho_solve(linalg.cho_factor(gram_matrix_ols), X.T.dot(y))\n",
    "    sigma_2_hat_ols = np.sum(np.square(y - X.dot(beta_hat_ols)))/(len(y) - len(beta_hat_ols))\n",
    "    \n",
    "    correlation_matrices = make_correlation_matrices(\n",
    "        clusters,\n",
    "        beta_hat_ols,\n",
    "        sigma_2_hat_ols)\n",
    "    beta_hats = estimate_beta_hats(clusters, correlation_matrices)\n",
    "    \n",
    "    if estimate_beta:\n",
    "        return beta_hats\n",
    "    \n",
    "    return {\n",
    "        method.name: {\n",
    "            correlation_structure: np.sqrt(estimate_covariance(\n",
    "                clusters,\n",
    "                [matrix_dict[correlation_structure] for matrix_dict in correlation_matrices],\n",
    "                method,\n",
    "                beta_hat)[1, 1])\n",
    "            for correlation_structure, beta_hat in beta_hats.items()\n",
    "        }\n",
    "        for method in EstimationMethod\n",
    "    }\n",
    "    \n",
    "    print(correlation_matrices[0])\n",
    "    print(correlation_matrices[1])\n",
    "        \n",
    "    return {\n",
    "        EstimationMethod.GLS.name: {\n",
    "            CorrelationStructure.NONE.name: 0, #np.sqrt(gram_matrix_inv[1, 1]),\n",
    "            CorrelationStructure.EXCHANGEABLE.name: 0.,\n",
    "            CorrelationStructure.EXPONENTIAL.name: 0.,\n",
    "        },\n",
    "        EstimationMethod.QL.name: {\n",
    "            CorrelationStructure.NONE.name: 0, #np.sqrt(gram_matrix_inv[1, 1]*sigma_2_hat),\n",
    "            CorrelationStructure.EXCHANGEABLE.name: 0.5,\n",
    "            CorrelationStructure.EXPONENTIAL.name: 0.,            \n",
    "        },\n",
    "        EstimationMethod.Sandwich.name: {\n",
    "            CorrelationStructure.NONE.name: 0,#np.sqrt(sandwich_variance[1, 1]),\n",
    "            CorrelationStructure.EXCHANGEABLE.name: 0.,\n",
    "            CorrelationStructure.EXPONENTIAL.name: 0.,\n",
    "        },\n",
    "    }\n",
    "\n",
    "def run_experiments(experiment, num_trials):                    \n",
    "    results = [run_experiment(experiment) for _ in range(num_trials)]\n",
    "    results = functools.reduce(sum_dict, results)\n",
    "    return divide_dict(results, num_trials)\n",
    "\n",
    "experiment = Experiment.from_template(\n",
    "    DESIGN_CLUSTERS['I'],\n",
    "    NUM_CLUSTERS[2],\n",
    "    WITHIN_CLUSTER_CORRELATIONS[0],\n",
    "    CorrelationStructure.EXPONENTIAL)\n",
    "\n",
    "tmp = run_experiments(experiment, 128)\n",
    "#tmp = run_experiment(experiment)\n",
    "#experiment.sample_clusters()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24412215, 0.01982407])"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hats = [\n",
    "    run_experiment(\n",
    "        experiment, estimate_beta=True)[CorrelationStructure.EXCHANGEABLE.name]\n",
    "    for _ in range(256)\n",
    "]\n",
    "np.sqrt(np.var(beta_hats, ddof=1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14966439122249486"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.02239943)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLS       NONE            0\n",
       "          EXCHANGEABLE    0\n",
       "          EXPONENTIAL     0\n",
       "QL        NONE            0\n",
       "          EXCHANGEABLE    0\n",
       "          EXPONENTIAL     0\n",
       "Sandwich  NONE            0\n",
       "          EXCHANGEABLE    0\n",
       "          EXPONENTIAL     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(tmp, orient='index').stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('OLS', 'EXCHANGEABLE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('OLS', 'EXPONENTIAL'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('OLS', 'NONE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('QL', 'EXCHANGEABLE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.5,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('QL', 'EXPONENTIAL'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('QL', 'NONE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.9,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('Sandwich', 'EXCHANGEABLE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('Sandwich', 'EXPONENTIAL'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan},\n",
       " ('Sandwich', 'NONE'): {(15, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (15, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (15, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (30, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.5): nan,\n",
       "  (30, 'II', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'I', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.5): nan,\n",
       "  (60, 'I', 'EXPONENTIAL', 0.9): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.5): nan,\n",
       "  (60, 'II', 'EXCHANGEABLE', 0.9): nan,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.5): 0.0,\n",
       "  (60, 'II', 'EXPONENTIAL', 0.9): nan}}"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def index_experiment(experiment):    \n",
    "    return (experiment.num_clusters,\n",
    "            [k for k, v in DESIGN_CLUSTERS.items() if experiment.clusters == v][0],\n",
    "            experiment.within_cluster_correlation_structure.name,\n",
    "            experiment.within_cluster_correlation)\n",
    "\n",
    "simulation_results = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product(\n",
    "        [NUM_CLUSTERS, DESIGN_CLUSTERS.keys(),\n",
    "         [CorrelationStructure.EXCHANGEABLE.name, CorrelationStructure.EXPONENTIAL.name],\n",
    "         WITHIN_CLUSTER_CORRELATIONS],\n",
    "        names=['$n$', 'Design', 'Correlation structure', 'Correlation']),\n",
    "    columns=pd.MultiIndex.from_product(\n",
    "        [[value.name for value in EstimationMethod],\n",
    "         [value.name for value in CorrelationStructure]],\n",
    "        names=['Estimator', 'Assumed correlation']\n",
    "    ))\n",
    "\n",
    "simulation_results.loc[index_experiment(experiment)] = (\n",
    "    pd.DataFrame.from_dict(tmp, orient='index').stack())\n",
    "simulation_results.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CorrelationStructure.NONE: 1>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-a7ccf15b157b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "np.random.choice([[7, 9], [2, 3], [1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.5, 0.5, 0.5],\n",
       "       [0.5, 1. , 0.5, 0.5],\n",
       "       [0.5, 0.5, 1. , 0.5],\n",
       "       [0.5, 0.5, 0.5, 1. ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linalg.cholesky(tmp).T.dot(linalg.cholesky(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6, -0.4, -0.4, -0.4],\n",
       "       [-0.4,  1.6, -0.4, -0.4],\n",
       "       [-0.4, -0.4,  1.6, -0.4],\n",
       "       [-0.4, -0.4, -0.4,  1.6]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linalg.inv(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28867513459481287"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3)/6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
