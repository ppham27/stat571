{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction of Chapter 2 Slide 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>age</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M01</th>\n",
       "      <td>26.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01</th>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01</th>\n",
       "      <td>29.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01</th>\n",
       "      <td>31.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02</th>\n",
       "      <td>21.5</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02</th>\n",
       "      <td>22.5</td>\n",
       "      <td>10</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02</th>\n",
       "      <td>23.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02</th>\n",
       "      <td>26.5</td>\n",
       "      <td>14</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         distance  age   Sex\n",
       "Subject                     \n",
       "M01          26.0    8  Male\n",
       "M01          25.0   10  Male\n",
       "M01          29.0   12  Male\n",
       "M01          31.0   14  Male\n",
       "M02          21.5    8  Male\n",
       "M02          22.5   10  Male\n",
       "M02          23.0   12  Male\n",
       "M02          26.5   14  Male"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthodont_data = pd.read_csv('orthodont.csv')\n",
    "orthodont_data = orthodont_data.set_index('Subject')\n",
    "orthodont_data.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_covariates(data_frame):    \n",
    "    age = (data_frame['age'] - 8).values\n",
    "    is_female = (data_frame['Sex'] == 'Female').values.astype(np.float64)\n",
    "    return np.column_stack((\n",
    "        np.ones(len(data_frame)),\n",
    "        age,\n",
    "        is_female,\n",
    "        age*is_female,        \n",
    "    ))\n",
    "\n",
    "def make_response(data_frame):\n",
    "    return data_frame['distance'].values\n",
    "\n",
    "X = tf.convert_to_tensor(\n",
    "    [make_covariates(orthodont_data.loc[i]) for i in np.unique(orthodont_data.index)],\n",
    "    tf.float32)\n",
    "y = tf.expand_dims(tf.convert_to_tensor(\n",
    "    [make_response(orthodont_data.loc[i]) for i in np.unique(orthodont_data.index)],\n",
    "    tf.float32), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_beta(X, y, weights):\n",
    "    projected_X = tf.reduce_sum(tf.matmul(tf.tensordot(tf.transpose(X, [0, 2, 1]), weights, 1), X), 0)\n",
    "    projected_y = tf.reduce_sum(tf.matmul(tf.tensordot(tf.transpose(X, [0, 2, 1]), weights, 1), y), 0)\n",
    "    return tf.linalg.cholesky_solve(tf.linalg.cholesky(projected_X), projected_y)\n",
    "\n",
    "def loss_fn(X, y, covariance, reml=False):\n",
    "    weights = tf.linalg.cholesky_solve(tf.linalg.cholesky(covariance), tf.eye(4))        \n",
    "    beta = solve_beta(X, y, weights)     \n",
    "    residuals = y - tf.tensordot(X, beta, 1)\n",
    "    weighted_squared_error = tf.matmul(\n",
    "        tf.tensordot(tf.transpose(residuals, [0, 2, 1]), weights, 1), residuals)\n",
    "    loss = tf.reduce_mean(weighted_squared_error) + tf.linalg.logdet(covariance)\n",
    "    \n",
    "    if reml:\n",
    "        reml_loss = tf.reduce_sum(tf.matmul(tf.tensordot(tf.transpose(X, [0, 2, 1]), weights, 1), X), 0)\n",
    "        return loss + tf.linalg.logdet(reml_loss) / tf.cast(tf.shape(y)[0], tf.float32)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compound Symmetric\n",
    "\n",
    "This means each cluster has exchangeable correlation structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.36787945, 0.36787945, 0.36787945],\n",
       "       [0.36787945, 1.        , 0.36787945, 0.36787945],\n",
       "       [0.36787945, 0.36787945, 1.        , 0.36787945],\n",
       "       [0.36787945, 0.36787945, 0.36787945, 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_standard_errors = tf.Variable([0., 0., 0., 0.])\n",
    "log_correlation = tf.Variable([-1.], dtype=tf.float32)\n",
    "\n",
    "def make_compound_symmetric_covariance(log_standard_errors, log_correlation):\n",
    "    rho = tf.exp(log_correlation)\n",
    "    correlation = tf.ones((4, 4), dtype=tf.float32)*rho + tf.eye(4)*(1. - rho)\n",
    "    standard_errors = tf.exp(log_standard_errors)\n",
    "    return correlation*standard_errors*tf.expand_dims(standard_errors, -1)\n",
    "\n",
    "make_compound_symmetric_covariance(log_standard_errors, log_correlation).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.341891 , 2.8692682, 3.472892 , 3.0481002],\n",
       "       [2.869268 , 3.9785721, 2.9971426, 2.6305428],\n",
       "       [3.472892 , 2.9971426, 5.828644 , 3.1839447],\n",
       "       [3.0481005, 2.630543 , 3.183945 , 4.4899707]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(0.1)\n",
    "variables = [log_standard_errors, log_correlation]\n",
    "\n",
    "for _ in range(2048):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(X, y, make_compound_symmetric_covariance(log_standard_errors, log_correlation))\n",
    "        gradients = tape.gradient(loss, variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "make_compound_symmetric_covariance(log_standard_errors, log_correlation).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.311253 , 0.6223863, 0.6223863, 0.6223863],\n",
       "       [0.6223863, 1.9946358, 0.6223863, 0.6223863],\n",
       "       [0.6223863, 0.6223863, 2.4142585, 0.6223863],\n",
       "       [0.6223863, 0.6223863, 0.6223863, 2.1189551]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_compound_symmetric_S(log_standard_errors, log_correlation):\n",
    "    S = np.diag(tf.exp(log_standard_errors).numpy())\n",
    "    S[S == 0] = tf.exp(log_correlation).numpy()\n",
    "    return S\n",
    "\n",
    "estimate_compound_symmetric_S(log_standard_errors, log_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resricted Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3867726, 0.6352883, 0.6352883, 0.6352883],\n",
       "       [0.6352883, 2.0582683, 0.6352883, 0.6352883],\n",
       "       [0.6352883, 0.6352883, 2.4678137, 0.6352883],\n",
       "       [0.6352883, 0.6352883, 0.6352883, 2.1967258]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_standard_errors = tf.Variable([0., 0., 0., 0.])\n",
    "log_correlation = tf.Variable([-1.], dtype=tf.float32)\n",
    "\n",
    "optimizer = tf.train.AdagradOptimizer(0.1)\n",
    "variables = [log_standard_errors, log_correlation]\n",
    "\n",
    "for _ in range(2048):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(X, y, make_compound_symmetric_covariance(log_standard_errors, log_correlation), reml=True)\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "estimate_compound_symmetric_S(log_standard_errors, log_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric\n",
    "\n",
    "This is an unstructured covariance matrix. It's only enforced that the covariance matrix is symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.36787945, 0.36787945, 0.36787945],\n",
       "       [0.36787945, 1.        , 0.36787945, 0.36787945],\n",
       "       [0.36787945, 0.36787945, 1.        , 0.36787945],\n",
       "       [0.36787945, 0.36787945, 0.36787945, 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_covariance = tf.Variable([0., -1., 0., -1., -1., 0., -1., -1., -1., 0.], dtype=tf.float32)\n",
    "\n",
    "def make_symmetric_covariance(log_covariance):\n",
    "    return tf.gather(tf.exp(log_covariance),\n",
    "                     [[0, 1, 3, 6], [1, 2, 4, 7], [3, 4, 5, 8], [6, 7, 8, 9]])\n",
    "\n",
    "make_symmetric_covariance(log_covariance).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.113675 , 2.4365215, 3.6041563, 2.5170095],\n",
       "       [2.4365215, 3.9241848, 2.7122397, 3.0578787],\n",
       "       [3.6041563, 2.7122397, 5.9719524, 3.8170369],\n",
       "       [2.5170095, 3.0578787, 3.8170369, 4.6125784]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(0.1)\n",
    "variables = [log_covariance]\n",
    "\n",
    "for _ in range(2048):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(X, y, make_symmetric_covariance(log_covariance))\n",
    "        gradients = tape.gradient(loss, variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "make_symmetric_covariance(log_covariance).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2613435 , 0.54391235, 0.6521971 , 0.51825845],\n",
       "       [0.5439124 , 1.9809556 , 0.5602672 , 0.718743  ],\n",
       "       [0.6521971 , 0.5602672 , 2.443758  , 0.727271  ],\n",
       "       [0.51825845, 0.7187431 , 0.7272711 , 2.1476912 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_symmetric_S(log_covariance):\n",
    "    symmetric_covariance = make_symmetric_covariance(log_covariance).numpy()\n",
    "    standard_errors = np.sqrt(np.diag(symmetric_covariance))\n",
    "    S = symmetric_covariance/standard_errors/standard_errors[:,np.newaxis]\n",
    "    S += np.diag(standard_errors) - np.eye(len(standard_errors))\n",
    "    return S\n",
    "\n",
    "estimate_symmetric_S(log_covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3269567, 0.5674492, 0.6582997, 0.5211466],\n",
       "       [0.5674493, 2.0452266, 0.5798044, 0.7243952],\n",
       "       [0.6582997, 0.5798044, 2.4997234, 0.7390662],\n",
       "       [0.5211466, 0.7243952, 0.7390661, 2.2305765]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_covariance = tf.Variable([0., -1., 0., -1., -1., 0., -1., -1., -1., 0.], dtype=tf.float32)\n",
    "\n",
    "optimizer = tf.train.AdagradOptimizer(0.1)\n",
    "variables = [log_covariance]\n",
    "\n",
    "for _ in range(2048):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(X, y, make_symmetric_covariance(log_covariance), reml=True)\n",
    "        gradients = tape.gradient(loss, variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "estimate_symmetric_S(log_covariance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
