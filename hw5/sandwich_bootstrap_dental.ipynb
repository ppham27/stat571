{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import sys\n",
    "from typing import Any, Callable, NamedTuple, Sequence, Tuple\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import gen_array_ops\n",
    "from tensorflow.python.ops import gen_linalg_ops\n",
    "from tensorflow.python.ops import parallel_for\n",
    "pfor = sys.modules['tensorflow.python.ops.parallel_for.pfor']\n",
    "\n",
    "tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pfor.RegisterPForWithArgs('MatrixBandPart', gen_array_ops.matrix_band_part)\n",
    "@pfor.RegisterPForWithArgs('MatrixDiag', gen_array_ops.matrix_diag)\n",
    "def _convert_matrix_diag(pfor_input, op_type, op_func):\n",
    "    del op_type\n",
    "    return pfor.wrap(op_func(*[x.t for x in pfor_input.inputs]), True)\n",
    "\n",
    "@pfor.RegisterPForWithArgs('MatrixSetDiag', gen_array_ops.matrix_set_diag)\n",
    "@pfor.RegisterPForWithArgs('MatrixTriangularSolve', gen_linalg_ops.matrix_triangular_solve)\n",
    "def _convert_matrix_solve(pfor_input, op_type, op_func):\n",
    "    del op_type\n",
    "    pfor_input.stack_inputs()\n",
    "    return pfor.wrap(op_func(*[x.t for x in pfor_input.inputs]), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>age</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M01</th>\n",
       "      <td>26.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01</th>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01</th>\n",
       "      <td>29.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01</th>\n",
       "      <td>31.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02</th>\n",
       "      <td>21.5</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02</th>\n",
       "      <td>22.5</td>\n",
       "      <td>10</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02</th>\n",
       "      <td>23.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M02</th>\n",
       "      <td>26.5</td>\n",
       "      <td>14</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         distance  age   Sex\n",
       "Subject                     \n",
       "M01          26.0    8  Male\n",
       "M01          25.0   10  Male\n",
       "M01          29.0   12  Male\n",
       "M01          31.0   14  Male\n",
       "M02          21.5    8  Male\n",
       "M02          22.5   10  Male\n",
       "M02          23.0   12  Male\n",
       "M02          26.5   14  Male"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthodont_data = pd.read_csv('../hw4/orthodont.csv')\n",
    "orthodont_data = orthodont_data.set_index('Subject')\n",
    "orthodont_data.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_covariates(data_frame):    \n",
    "    age = (data_frame['age'] - 8).values\n",
    "    is_female = (data_frame['Sex'] == 'Female').values.astype(np.float64)\n",
    "    return np.column_stack((\n",
    "        np.ones(len(data_frame)),\n",
    "        age,\n",
    "        is_female,\n",
    "        age*is_female,        \n",
    "    ))\n",
    "\n",
    "def make_response(data_frame):\n",
    "    return data_frame['distance'].values\n",
    "\n",
    "X = tf.convert_to_tensor(\n",
    "    [make_covariates(orthodont_data.loc[i]) for i in np.unique(orthodont_data.index)],\n",
    "    tf.float32)\n",
    "y = tf.expand_dims(tf.convert_to_tensor(\n",
    "    [make_response(orthodont_data.loc[i]) for i in np.unique(orthodont_data.index)],\n",
    "    tf.float32), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Correlation Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_covariance_homoscedastic(log_variance):\n",
    "    \"\"\"Makes diagonal homoscedastic covariance structure.\"\"\"\n",
    "    return tf.exp(log_variance)*tf.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_covariance_exchangeable(log_covariance_params):\n",
    "    \"\"\"Makes heteroscedastic, exchangeble covariance structure.\"\"\"\n",
    "    standard_errors = tf.exp(log_covariance_params[:-1])  # First entries are standard errors.\n",
    "    rho = tf.exp(log_covariance_params[-1])  # Last entry is correlation.\n",
    "    correlation = tf.ones((4, 4), dtype=tf.float32)*rho + tf.eye(4)*(1. - rho)\n",
    "    return correlation*standard_errors*tf.expand_dims(standard_errors, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REML Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_beta(X, y, weights):\n",
    "    projected_X = tf.reduce_sum(tf.matmul(tf.tensordot(tf.transpose(X, [0, 2, 1]), weights, 1), X), 0)\n",
    "    projected_y = tf.reduce_sum(tf.matmul(tf.tensordot(tf.transpose(X, [0, 2, 1]), weights, 1), y), 0)\n",
    "    return tf.linalg.cholesky_solve(tf.linalg.cholesky(projected_X), projected_y)\n",
    "\n",
    "def loss_fn(X, y, covariance):\n",
    "    weights = tf.linalg.cholesky_solve(tf.linalg.cholesky(covariance), tf.eye(4))        \n",
    "    beta = solve_beta(X, y, weights)     \n",
    "    residuals = y - tf.tensordot(X, beta, 1)\n",
    "    weighted_squared_error = tf.matmul(\n",
    "        tf.tensordot(tf.transpose(residuals, [0, 2, 1]), weights, 1), residuals)\n",
    "    loss = tf.reduce_mean(weighted_squared_error) + tf.linalg.logdet(covariance)    \n",
    "    reml_loss = tf.reduce_sum(tf.matmul(tf.tensordot(tf.transpose(X, [0, 2, 1]), weights, 1), X), 0)\n",
    "    return loss + tf.linalg.logdet(reml_loss) / tf.cast(tf.shape(y)[0], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Minimizes REML loss with Newton-Raphson algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovarianceSpec(NamedTuple('CovarianceSpec', [\n",
    "    ('initial_params', np.array),\n",
    "    ('make_covariance', Callable[[tf.Tensor], tf.Tensor]),\n",
    "])):\n",
    "    \"\"\"Encapsulates covariance parameters.\"\"\"\n",
    "\n",
    "def fit(X, y, covariance_spec):\n",
    "    covariance_params = tf.Variable(covariance_spec.initial_params)\n",
    "    for i in range(16):\n",
    "        with tf.GradientTape(persistent=True) as outer_tape:\n",
    "            with tf.GradientTape() as inner_tape:\n",
    "                loss = loss_fn(X, y, covariance_spec.make_covariance(covariance_params))\n",
    "            gradients = inner_tape.gradient(loss, covariance_params)\n",
    "        hessian = outer_tape.jacobian(gradients, covariance_params,\n",
    "                                      parallel_iterations=4, experimental_use_pfor=False)            \n",
    "        covariance_params.assign_add(tf.reshape(\n",
    "            tf.linalg.cholesky_solve(tf.linalg.cholesky(hessian), -tf.expand_dims(gradients, -1)),\n",
    "            covariance_params.shape))\n",
    "    return covariance_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.256949], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_variance = fit(\n",
    "    X, y,\n",
    "    CovarianceSpec(initial_params=[0.], make_covariance=make_covariance_homoscedastic))\n",
    "tf.sqrt(tf.exp(log_variance)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Error Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_covariance(X, weights):\n",
    "    covariance = tf.reduce_sum(tf.matmul(tf.tensordot(tf.transpose(X, [0, 2, 1]), weights, 1), X), 0)\n",
    "    return tf.linalg.cholesky_solve(tf.linalg.cholesky(covariance), tf.eye(tf.shape(covariance)[0]))\n",
    "\n",
    "def sandwich_covariance(X, y, weights):\n",
    "    bread = ml_covariance(X, weights)\n",
    "    left_meat = tf.tensordot(tf.transpose(X, [0, 2, 1]), weights, 1)\n",
    "    right_meat =  tf.transpose(left_meat, [0, 2, 1])    \n",
    "    residuals = y - tf.tensordot(X, solve_beta(X, y, weights), 1)\n",
    "    residuals = tf.matmul(residuals, tf.transpose(residuals, [0, 2, 1]))\n",
    "    meat = tf.reduce_sum(tf.matmul(tf.matmul(left_meat, residuals), right_meat), 0)    \n",
    "    return tf.matmul(tf.matmul(bread, meat), bread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandwich_covariance_estimate = sandwich_covariance(\n",
    "    X, y,\n",
    "    tf.linalg.cholesky_solve(tf.linalg.cholesky(\n",
    "        make_covariance_homoscedastic(log_variance)), tf.eye(X.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28468183, -0.02929138, -0.28468183,  0.02929138],\n",
       "       [-0.02929133,  0.00967223,  0.02929132, -0.00967223],\n",
       "       [-0.2846818 ,  0.02929136,  0.5987651 , -0.02658853],\n",
       "       [ 0.02929131, -0.00967222, -0.02658838,  0.01365793]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandwich_covariance_estimate.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=418949, shape=(27, 4, 4), dtype=float32, numpy=\n",
       " array([[[1., 4., 0., 0.],\n",
       "         [1., 6., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 2., 0., 0.]],\n",
       " \n",
       "        [[1., 4., 0., 0.],\n",
       "         [1., 2., 0., 0.],\n",
       "         [1., 2., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       " \n",
       "        [[1., 6., 1., 6.],\n",
       "         [1., 2., 1., 2.],\n",
       "         [1., 0., 1., 0.],\n",
       "         [1., 4., 1., 4.]],\n",
       " \n",
       "        [[1., 6., 1., 6.],\n",
       "         [1., 0., 1., 0.],\n",
       "         [1., 4., 1., 4.],\n",
       "         [1., 2., 1., 2.]],\n",
       " \n",
       "        [[1., 4., 0., 0.],\n",
       "         [1., 6., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 6., 0., 0.]],\n",
       " \n",
       "        [[1., 0., 1., 0.],\n",
       "         [1., 6., 1., 6.],\n",
       "         [1., 6., 1., 6.],\n",
       "         [1., 4., 1., 4.]],\n",
       " \n",
       "        [[1., 4., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 6., 0., 0.],\n",
       "         [1., 4., 0., 0.]],\n",
       " \n",
       "        [[1., 6., 0., 0.],\n",
       "         [1., 2., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 6., 0., 0.]],\n",
       " \n",
       "        [[1., 0., 1., 0.],\n",
       "         [1., 4., 1., 4.],\n",
       "         [1., 0., 1., 0.],\n",
       "         [1., 0., 1., 0.]],\n",
       " \n",
       "        [[1., 4., 0., 0.],\n",
       "         [1., 6., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 4., 0., 0.]],\n",
       " \n",
       "        [[1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.],\n",
       "         [1., 4., 1., 4.],\n",
       "         [1., 0., 1., 0.]],\n",
       " \n",
       "        [[1., 2., 1., 2.],\n",
       "         [1., 6., 1., 6.],\n",
       "         [1., 0., 1., 0.],\n",
       "         [1., 2., 1., 2.]],\n",
       " \n",
       "        [[1., 2., 0., 0.],\n",
       "         [1., 2., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 2., 0., 0.]],\n",
       " \n",
       "        [[1., 2., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 6., 0., 0.]],\n",
       " \n",
       "        [[1., 6., 0., 0.],\n",
       "         [1., 2., 0., 0.],\n",
       "         [1., 6., 0., 0.],\n",
       "         [1., 4., 0., 0.]],\n",
       " \n",
       "        [[1., 2., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 6., 0., 0.]],\n",
       " \n",
       "        [[1., 4., 0., 0.],\n",
       "         [1., 2., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 2., 0., 0.]],\n",
       " \n",
       "        [[1., 2., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 6., 0., 0.]],\n",
       " \n",
       "        [[1., 2., 1., 2.],\n",
       "         [1., 0., 1., 0.],\n",
       "         [1., 0., 1., 0.],\n",
       "         [1., 6., 1., 6.]],\n",
       " \n",
       "        [[1., 4., 0., 0.],\n",
       "         [1., 2., 0., 0.],\n",
       "         [1., 6., 0., 0.],\n",
       "         [1., 4., 0., 0.]],\n",
       " \n",
       "        [[1., 2., 1., 2.],\n",
       "         [1., 6., 1., 6.],\n",
       "         [1., 2., 1., 2.],\n",
       "         [1., 0., 1., 0.]],\n",
       " \n",
       "        [[1., 4., 1., 4.],\n",
       "         [1., 0., 1., 0.],\n",
       "         [1., 4., 1., 4.],\n",
       "         [1., 2., 1., 2.]],\n",
       " \n",
       "        [[1., 2., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 2., 0., 0.]],\n",
       " \n",
       "        [[1., 4., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 6., 0., 0.]],\n",
       " \n",
       "        [[1., 4., 1., 4.],\n",
       "         [1., 0., 1., 0.],\n",
       "         [1., 4., 1., 4.],\n",
       "         [1., 4., 1., 4.]],\n",
       " \n",
       "        [[1., 4., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 6., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       " \n",
       "        [[1., 6., 0., 0.],\n",
       "         [1., 6., 0., 0.],\n",
       "         [1., 4., 0., 0.],\n",
       "         [1., 0., 0., 0.]]], dtype=float32)>,\n",
       " <tf.Tensor: id=418953, shape=(27, 4, 1), dtype=float32, numpy=\n",
       " array([[[25.5],\n",
       "         [26. ],\n",
       "         [25.5],\n",
       "         [25.5]],\n",
       " \n",
       "        [[31. ],\n",
       "         [28. ],\n",
       "         [28. ],\n",
       "         [27.5]],\n",
       " \n",
       "        [[26. ],\n",
       "         [24. ],\n",
       "         [20.5],\n",
       "         [24.5]],\n",
       " \n",
       "        [[28. ],\n",
       "         [24.5],\n",
       "         [28. ],\n",
       "         [25. ]],\n",
       " \n",
       "        [[23.5],\n",
       "         [25. ],\n",
       "         [22. ],\n",
       "         [25. ]],\n",
       " \n",
       "        [[23.5],\n",
       "         [26.5],\n",
       "         [26.5],\n",
       "         [25. ]],\n",
       " \n",
       "        [[23.5],\n",
       "         [22. ],\n",
       "         [25. ],\n",
       "         [23.5]],\n",
       " \n",
       "        [[26.5],\n",
       "         [22. ],\n",
       "         [22. ],\n",
       "         [26.5]],\n",
       " \n",
       "        [[21.5],\n",
       "         [23. ],\n",
       "         [21.5],\n",
       "         [21.5]],\n",
       " \n",
       "        [[31. ],\n",
       "         [31.5],\n",
       "         [31. ],\n",
       "         [31. ]],\n",
       " \n",
       "        [[23. ],\n",
       "         [23. ],\n",
       "         [23.5],\n",
       "         [23. ]],\n",
       " \n",
       "        [[21. ],\n",
       "         [21.5],\n",
       "         [20. ],\n",
       "         [21. ]],\n",
       " \n",
       "        [[21.5],\n",
       "         [21.5],\n",
       "         [24.5],\n",
       "         [21.5]],\n",
       " \n",
       "        [[20.5],\n",
       "         [23. ],\n",
       "         [23. ],\n",
       "         [26. ]],\n",
       " \n",
       "        [[26.5],\n",
       "         [22. ],\n",
       "         [26.5],\n",
       "         [24.5]],\n",
       " \n",
       "        [[22.5],\n",
       "         [23. ],\n",
       "         [21.5],\n",
       "         [26.5]],\n",
       " \n",
       "        [[24. ],\n",
       "         [23.5],\n",
       "         [24. ],\n",
       "         [23.5]],\n",
       " \n",
       "        [[23.5],\n",
       "         [24. ],\n",
       "         [21.5],\n",
       "         [28. ]],\n",
       " \n",
       "        [[21.5],\n",
       "         [21. ],\n",
       "         [21. ],\n",
       "         [25.5]],\n",
       " \n",
       "        [[29. ],\n",
       "         [25. ],\n",
       "         [31. ],\n",
       "         [29. ]],\n",
       " \n",
       "        [[25. ],\n",
       "         [28. ],\n",
       "         [25. ],\n",
       "         [24.5]],\n",
       " \n",
       "        [[25. ],\n",
       "         [23.5],\n",
       "         [25. ],\n",
       "         [24.5]],\n",
       " \n",
       "        [[28. ],\n",
       "         [31. ],\n",
       "         [31. ],\n",
       "         [28. ]],\n",
       " \n",
       "        [[31. ],\n",
       "         [31. ],\n",
       "         [23. ],\n",
       "         [26. ]],\n",
       " \n",
       "        [[24. ],\n",
       "         [21. ],\n",
       "         [24. ],\n",
       "         [24. ]],\n",
       " \n",
       "        [[23.5],\n",
       "         [23.5],\n",
       "         [25. ],\n",
       "         [22. ]],\n",
       " \n",
       "        [[26. ],\n",
       "         [26. ],\n",
       "         [22.5],\n",
       "         [20. ]]], dtype=float32)>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SamplingStrategy(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, clusters: Tuple[tf.Tensor, tf.Tensor]):\n",
    "        pass\n",
    "    \n",
    "class ClusterSampler(SamplingStrategy):\n",
    "    def __call__(self, clusters):\n",
    "        sample = np.random.choice(len(clusters), len(clusters), replace=True)\n",
    "        return tuple([tf.gather(item, sample) for item in clusters])\n",
    "    \n",
    "class IndependentSampler(SamplingStrategy):\n",
    "    def __call__(self, clusters):\n",
    "        size = tf.reduce_prod(tf.shape(clusters[0])[:-1]).numpy()\n",
    "        sample = np.random.choice(size, size, replace=True)\n",
    "        return tuple([self._sample(item, sample) for item in clusters])\n",
    "    \n",
    "    def _sample(self, tensor: tf.Tensor, indices: np.array):\n",
    "        original_shape = tf.shape(tensor)\n",
    "        tensor = tf.reshape(tensor, (len(indices), -1))\n",
    "        return tf.reshape(tf.gather(tensor, indices), original_shape)\n",
    "    \n",
    "class HierarchicalSampler(SamplingStrategy):\n",
    "    def __call__(self, clusters):\n",
    "        shape = tf.shape(clusters[0]).numpy()\n",
    "        size = 1        \n",
    "        samples = []\n",
    "        for s in shape[:-1]:\n",
    "            size *= s\n",
    "            samples.append(np.random.choice(s, size, replace=True))\n",
    "        \n",
    "        sample = []\n",
    "        for i in range(len(samples[-1])):\n",
    "            indices = [samples[-1][i]]\n",
    "            for j in range(len(shape) - 3, -1, -1):\n",
    "                indices.append(samples[j][i//s])\n",
    "            sample.append(tuple(reversed(indices)))\n",
    "                        \n",
    "        return tuple([tf.reshape(tf.gather_nd(item, sample), item.shape) for item in clusters])\n",
    "        \n",
    "#ClusterSampler()((X, y))\n",
    "#IndependentSampler()((X, y))\n",
    "HierarchicalSampler()((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip([1], [1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REML Exchangeable Test\n",
    "\n",
    "Should agree with numbers from Chapter 2, slides 73 and 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3867779 , 2.058272  , 2.4678187 , 2.19673   , 0.63528943],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_exchangeable_covariance_params = fit(\n",
    "    X, y,\n",
    "    CovarianceSpec(initial_params=[0., 0., 0., 0., -1.],\n",
    "                   make_covariance=make_covariance_exchangeable))\n",
    "tf.exp(log_exchangeable_covariance_params).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=418373, shape=(4, 1), dtype=float32, numpy=\n",
       "array([[22.485374  ],\n",
       "       [ 0.79431295],\n",
       "       [-1.2507197 ],\n",
       "       [-0.3155596 ]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_beta(X, y, tf.linalg.cholesky_solve(\n",
    "    tf.linalg.cholesky(\n",
    "        make_covariance_exchangeable(log_exchangeable_covariance_params)),\n",
    "    tf.eye(X.shape[-1])))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5308524 , 0.07701091, 0.8316859 , 0.12065291], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(tf.linalg.diag_part(\n",
    "    ml_covariance(X, tf.linalg.cholesky_solve(\n",
    "        tf.linalg.cholesky(\n",
    "            make_covariance_exchangeable(log_exchangeable_covariance_params)),\n",
    "        tf.eye(X.shape[-1]))))).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
